# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_AUN4WZ-OTa5zF3MO1x0v4UYo_1wsR-w
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df_movie=pd.read_csv('/content/movies.dat',sep='::',engine='python', encoding='latin1')
df_movie.dropna(inplace=True)
df_movie.head()

df_movie.shape

df_movie.describe()

df_movie.isna().sum()

df_ratings=pd.read_csv('/content/ratings.dat',sep='::',engine='python', encoding='latin1')
df_ratings.dropna(inplace=True)
df_ratings.head(10)

df_ratings.shape

df_ratings.describe()

df_ratings.isna().sum()

df_users=pd.read_csv('/content/users.dat',sep='::',engine='python',encoding='latin1')
df_users.dropna(inplace=True)
df_users.head()

df_users.shape

df_users.describe()

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
df_users['F']=labelencoder.fit_transform(df_users['F'])
df_users.head()

"""user id as 1
Gender as F
Age as 1.1
occupation as 10
zip-code as 48067

"""

df_users.isna().sum()

df_data=pd.concat([df_movie,df_ratings,df_users],axis=1)
df_data.dropna()
df_data.head(10)

df_data.shape

df2=df_data.drop(['10','48067','978300760'],axis=1)
df2.head()

df2.describe()

df2.isna().sum()

df_final=df2.dropna()

df_final.shape

sns.countplot(x=df_final['F'],hue=df_final['5'])

df_final['1.1'].plot.hist(bins=25)
plt.ylabel('Number of Users')
plt.xlabel('Age')

df_final['5'].value_counts().plot(kind='bar')
plt.show()

df_final.iloc[:, 0].plot.hist(bins=25)
plt.xlabel('MovieID')
plt.ylabel('Ratings')

df_final['1.1'].plot.hist(bins=25)
plt.xlabel('Age')
plt.ylabel('Number of Users')

sns.countplot(x=df_final['1.1'],hue=df_final['5'])

df_final.head()

input=df_final.iloc[:, [3, 4, 7, 8]]
target=df_final.iloc[:, 5]

target.head()

input.head()

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
Scaled_data=scaler.fit_transform(input)
scaler_df=pd.DataFrame(Scaled_data,columns=input.columns)
scaler_df.head()

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(Scaled_data,target,test_size=0.3)

print(Y_train)

print(Y_test)

from sklearn.linear_model import LinearRegression, LogisticRegression
model=LogisticRegression()
model.fit(X_train,Y_train)

model.predict(X_test)

print(Y_test)